{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Tạo folder data để các bạn upload file 3 file data được tạo ra ở step 0 vào folder data\n",
        "# Các bạn upload file hand_gesture.yaml ngoài folder data\n",
        "!mkdir data/"
      ],
      "metadata": {
        "id": "JZJH1v68YX4M",
        "outputId": "7d8300f4-f7d4-48ad-8d47-267cbf14b3dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘data/’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Nếu đã chạy thành công step 0 thì các bạn không chạy cell này và chỉ upload 3 file data của các bạn vào thư mục data\n",
        "# Và upload file hand_gesture.yaml bên ngoài thư mục data\n",
        "# Nếu không chạy được ở step 0 thì các bạn run cell này để download data\n",
        "!gdown  1gzWOtABiVmJ38usCSDe5F9gR2tECt3zu -O data/\n",
        "!gdown  15lwipssmC_K82ukRfb0uVCiDH1TZ3QCf -O data/\n",
        "!gdown  1nIo1_wBmkovz-u_BCsV5c1Kbz6ZqoKwq -O data/\n",
        "# Download file hand_gesture.yam\n",
        "!gdown  1ZteHYSgbuZu_GcUJHW8ZzoZv1DE8-oLw"
      ],
      "metadata": {
        "id": "L9QZbsqlXKvu",
        "outputId": "847f3539-aa2a-44ef-c8e9-561c48790433",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1gzWOtABiVmJ38usCSDe5F9gR2tECt3zu\n",
            "To: /content/data/landmark_val.csv\n",
            "100% 369k/369k [00:00<00:00, 138MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=15lwipssmC_K82ukRfb0uVCiDH1TZ3QCf\n",
            "To: /content/data/landmark_train.csv\n",
            "100% 1.28M/1.28M [00:00<00:00, 175MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1nIo1_wBmkovz-u_BCsV5c1Kbz6ZqoKwq\n",
            "To: /content/data/landmark_test.csv\n",
            "100% 320k/320k [00:00<00:00, 55.2MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ZteHYSgbuZu_GcUJHW8ZzoZv1DE8-oLw\n",
            "To: /content/hand_gesture.yaml\n",
            "100% 120/120 [00:00<00:00, 528kB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mediapipe==0.10.18"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqhc2257_m3K",
        "outputId": "74672fee-504f-4a9f-a03b-c261615955d3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mediapipe==0.10.18 in /usr/local/lib/python3.10/dist-packages (0.10.18)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mediapipe==0.10.18) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe==0.10.18) (24.2.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe==0.10.18) (24.3.25)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (from mediapipe==0.10.18) (0.4.33)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (from mediapipe==0.10.18) (0.4.33)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mediapipe==0.10.18) (3.8.0)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.10/dist-packages (from mediapipe==0.10.18) (1.26.4)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mediapipe==0.10.18) (4.10.0.84)\n",
            "Requirement already satisfied: protobuf<5,>=4.25.3 in /usr/local/lib/python3.10/dist-packages (from mediapipe==0.10.18) (4.25.5)\n",
            "Requirement already satisfied: sounddevice>=0.4.4 in /usr/local/lib/python3.10/dist-packages (from mediapipe==0.10.18) (0.5.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from mediapipe==0.10.18) (0.2.0)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->mediapipe==0.10.18) (1.17.1)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe==0.10.18) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe==0.10.18) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.10 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe==0.10.18) (1.13.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe==0.10.18) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe==0.10.18) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe==0.10.18) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe==0.10.18) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe==0.10.18) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe==0.10.18) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe==0.10.18) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe==0.10.18) (2.8.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe==0.10.18) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe==0.10.18) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQmMu4bKVnkG",
        "outputId": "72f4e9dc-ffc5-40f6-e101-b7839ea8184c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.10/dist-packages (1.6.0)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.26.4)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (24.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.5.1+cu121)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (0.11.9)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.0.0->torchmetrics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import yaml\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from  torch import nn\n",
        "import mediapipe as mp\n",
        "from torch import optim\n",
        "from datetime import datetime\n",
        "from torchmetrics import Accuracy\n",
        "from torch.utils.data import Dataset"
      ],
      "metadata": {
        "id": "xZPTB4Gm_8KF"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        list_label = label_dict_from_config_file(\"hand_gesture.yaml\")\n",
        "\n",
        "        self.linear_relu_stack = nn.Sequential(nn.Linear(63,128),\n",
        "                                               nn.ReLU(),\n",
        "                                               nn.BatchNorm1d(128),\n",
        "                                               nn.Dropout(0.4),\n",
        "                                               nn.Linear(128,128),\n",
        "                                               nn.ReLU(),\n",
        "                                               nn.Dropout(0.4),\n",
        "                                               nn.Linear(128,128),\n",
        "                                               nn.ReLU(),\n",
        "                                               nn.Dropout(0.6),\n",
        "                                               nn.Linear(128,len(list_label)),\n",
        "                                               )\n",
        "\n",
        "    def forward(self, x):\n",
        "        ################## Your Code Here ################## Q2\n",
        "        ''' Hoàn thành code để thực hiện forward dự đoán cử chỉ với input x.\n",
        "        Thực hiệnt flatten x\n",
        "        Pass x vừa flatten vào linear_relu_stack\n",
        "        Return  logits (outputs từ layer cuối cùng)\n",
        "        '''\n",
        "        ####################################################\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "    def predict(self,x,threshold=0.8):\n",
        "        logits = self(x)\n",
        "        softmax_prob = nn.Softmax(dim=1)(logits)\n",
        "        chosen_ind = torch.argmax(softmax_prob,dim=1)\n",
        "        return torch.where(softmax_prob[0,chosen_ind]>threshold,chosen_ind,-1)\n",
        "\n",
        "    def predict_with_known_class(self,x):\n",
        "        logits = self(x)\n",
        "        softmax_prob = nn.Softmax(dim=1)(logits)\n",
        "        return torch.argmax(softmax_prob,dim=1)\n",
        "\n",
        "    def score(self,logits):\n",
        "        return -torch.amax(logits,dim=1)"
      ],
      "metadata": {
        "id": "qdI0AaZt_38Q"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def label_dict_from_config_file(relative_path):\n",
        "    with open(relative_path,\"r\") as f:\n",
        "       label_tag = yaml.full_load(f)[\"gestures\"]\n",
        "    return label_tag"
      ],
      "metadata": {
        "id": "lJUGNVftADWJ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HandLandmarksDetector():\n",
        "    def __init__(self) -> None:\n",
        "        self.mp_drawing = mp.solutions.drawing_utils\n",
        "        self.mp_drawing_styles = mp.solutions.drawing_styles\n",
        "        self.mp_hands = mp.solutions.hands\n",
        "        self.detector = self.mp_hands.Hands(False,max_num_hands=1,min_detection_confidence=0.5)\n",
        "\n",
        "    def detectHand(self,frame):\n",
        "        hands = []\n",
        "        frame = cv2.flip(frame, 1)\n",
        "        annotated_image = frame.copy()\n",
        "        results = self.detector.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "        if results.multi_hand_landmarks is not None:\n",
        "            for hand_landmarks in results.multi_hand_landmarks:\n",
        "                hand = []\n",
        "                self.mp_drawing.draw_landmarks(\n",
        "                    annotated_image,\n",
        "                    hand_landmarks,\n",
        "                    self.mp_hands.HAND_CONNECTIONS,\n",
        "                    self.mp_drawing_styles.get_default_hand_landmarks_style(),\n",
        "                    self.mp_drawing_styles.get_default_hand_connections_style())\n",
        "                for landmark in hand_landmarks.landmark:\n",
        "                    x,y,z = landmark.x,landmark.y,landmark.z\n",
        "                    hand.extend([x,y,z])\n",
        "            hands.append(hand)\n",
        "        return hands,annotated_image"
      ],
      "metadata": {
        "id": "3yzD6r0wTR0v"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, data_file):\n",
        "        self.data = pd.read_csv(data_file)\n",
        "        self.labels = torch.from_numpy(self.data.iloc[:,0].to_numpy())\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        one_hot_label = self.labels[idx]\n",
        "        torch_data = torch.from_numpy(self.data.iloc[idx,1:].to_numpy(dtype=np.float32))\n",
        "        return torch_data, one_hot_label"
      ],
      "metadata": {
        "id": "DQH1LReLB03s"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EarlyStopper:\n",
        "    def __init__(self, patience=1, min_delta=0):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.counter = 0\n",
        "        self.watched_metrics = np.inf\n",
        "\n",
        "    def early_stop(self, current_value):\n",
        "        if current_value < self.watched_metrics:\n",
        "            self.watched_metrics = current_value\n",
        "            self.counter = 0\n",
        "        elif current_value > (self.watched_metrics + self.min_delta):\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                return True\n",
        "        return False"
      ],
      "metadata": {
        "id": "h9prQCqNTXPS"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(trainloader, val_loader, model, loss_function, early_stopper, optimizer):\n",
        "    # add auroc score\n",
        "    best_vloss = 1_000_000\n",
        "    timestamp = datetime.now().strftime('%d-%m %H:%M')\n",
        "    for epoch in range(300):\n",
        "        #training step\n",
        "        model.train(True)\n",
        "        running_loss = 0.0\n",
        "        acc_train = Accuracy(num_classes=len(LIST_LABEL), task='MULTICLASS')\n",
        "        for batch_number,data in enumerate(trainloader):\n",
        "            inputs,labels = data\n",
        "\n",
        "            ################## Your Code Here ################## Q9\n",
        "            ''' Hoàn thành code để thực hiện reset gradients và dự đoán class cử\n",
        "            chỉ của inputs\n",
        "            '''\n",
        "            optimizer.zero_grad()\n",
        "            preds = model(inputs)\n",
        "            ####################################################\n",
        "\n",
        "            ################## Your Code Here ################## Q10\n",
        "            ''' Hoàn thành code để thực hiện tính loss dưa vào kết quả dự đoán\n",
        "            và labels, sau đó thực hiện backwward và update parameters thông qua\n",
        "            optimizer\n",
        "            '''\n",
        "            loss = loss_function(preds,labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "\n",
        "            ####################################################\n",
        "\n",
        "            acc_train.update(model.predict_with_known_class(inputs), labels)\n",
        "            running_loss += loss.item()\n",
        "        avg_loss = running_loss / len(trainloader)\n",
        "        # validating step\n",
        "        model.train(False)\n",
        "        running_vloss = 0.0\n",
        "        acc_val = Accuracy(num_classes=len(LIST_LABEL), task='MULTICLASS')\n",
        "        for i, vdata in enumerate(val_loader):\n",
        "            vinputs, vlabels = vdata\n",
        "            preds = model(vinputs)\n",
        "            vloss = loss_function(preds, vlabels)\n",
        "            running_vloss += vloss.item()\n",
        "            acc_val.update(model.predict_with_known_class(vinputs), vlabels)\n",
        "\n",
        "        # Log the running loss averaged per batch\n",
        "        # for both training and validation\n",
        "        print(f\"Epoch {epoch}: \")\n",
        "        print(f\"Accuracy train:{acc_train.compute().item()}, val:{acc_val.compute().item()}\")\n",
        "        avg_vloss = running_vloss / len(val_loader)\n",
        "        print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
        "        print('Training vs. Validation Loss',\n",
        "                        { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
        "                        epoch + 1)\n",
        "        print('Training vs. Validation accuracy',\n",
        "                        { 'Training' : acc_train.compute().item()\n",
        "                        , 'Validation' : acc_val.compute().item() },\n",
        "                        epoch + 1)\n",
        "\n",
        "        # Track best performance, and save the model's state\n",
        "        if avg_vloss < best_vloss:\n",
        "            best_vloss = avg_vloss\n",
        "            best_model_path = f'./{save_path}/model_{timestamp}_{model.__class__.__name__}_best'\n",
        "            torch.save(model.state_dict(), best_model_path)\n",
        "\n",
        "        if early_stopper.early_stop(avg_vloss):\n",
        "            ################## Your Code Here ################## Q5\n",
        "            ''' Hoàn thành đoạn code bên dướ để  print ra epoch hiện tại và\n",
        "            minimum watched metric và thoát loop\n",
        "            '''\n",
        "            print(f\"Early stopping at epoch {epoch}\")\n",
        "            break\n",
        "\n",
        "            ####################################################\n",
        "\n",
        "\n",
        "\n",
        "    model_path = f'./{save_path}/model_{timestamp}_{model.__class__.__name__}_last'\n",
        "    torch.save(model.state_dict(), model_path)\n",
        "\n",
        "    print(acc_val.compute())\n",
        "    return model, best_model_path"
      ],
      "metadata": {
        "id": "fPBj338O_tcY"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_FOLDER_PATH=\"./data/\"\n",
        "LIST_LABEL = label_dict_from_config_file(\"hand_gesture.yaml\")\n",
        "train_path = os.path.join(DATA_FOLDER_PATH,\"landmark_train.csv\")\n",
        "val_path = os.path.join(DATA_FOLDER_PATH,\"landmark_val.csv\")\n",
        "save_path = './models'\n",
        "os.makedirs(save_path,exist_ok=True)\n",
        "\n",
        "trainset = CustomImageDataset(train_path)\n",
        "################## Your Code Here ################## Q3\n",
        "trainloader = torch.utils.data.DataLoader(trainset,batch_size=40, shuffle=True)\n",
        "####################################################\n",
        "\n",
        "valset = CustomImageDataset(os.path.join(val_path))\n",
        "val_loader = torch.utils.data.DataLoader(valset,batch_size=50, shuffle=False)\n",
        "\n",
        "################## Your Code Here ################## Q8\n",
        "'''Hoàn thành code để thực hiện khởi tạo NeuralNetwork model đã xây dựng ở trên,\n",
        "khởi tạo hàm loss sử dụng CrossEntropyLoss và khởi tạo early stopper với patience\n",
        "là 30 và min_delta là 0.01\n",
        "'''\n",
        "model = NeuralNetwork()\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "early_stopper = EarlyStopper(patience=30, min_delta=0.01)\n",
        "####################################################\n",
        "\n",
        "################## Your Code Here ################## Q4\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "####################################################\n",
        "\n",
        "\n",
        "model, best_model_path = train(trainloader, val_loader, model, loss_function, early_stopper, optimizer)"
      ],
      "metadata": {
        "id": "MhE1acacBG8z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35033a5d-7992-4fb9-efca-d489bfa937fb"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: \n",
            "Accuracy train:0.4592737853527069, val:0.5051194429397583\n",
            "LOSS train 1.4368269122563875 valid 1.3888428608576457\n",
            "Training vs. Validation Loss {'Training': 1.4368269122563875, 'Validation': 1.3888428608576457} 1\n",
            "Training vs. Validation accuracy {'Training': 0.4592737853527069, 'Validation': 0.5051194429397583} 1\n",
            "Epoch 1: \n",
            "Accuracy train:0.6967615485191345, val:0.8225256204605103\n",
            "LOSS train 0.8944166119282062 valid 0.6343306029836336\n",
            "Training vs. Validation Loss {'Training': 0.8944166119282062, 'Validation': 0.6343306029836336} 2\n",
            "Training vs. Validation accuracy {'Training': 0.6967615485191345, 'Validation': 0.8225256204605103} 2\n",
            "Epoch 2: \n",
            "Accuracy train:0.8743866682052612, val:0.9385665655136108\n",
            "LOSS train 0.4423379519811043 valid 0.2607491527063151\n",
            "Training vs. Validation Loss {'Training': 0.4423379519811043, 'Validation': 0.2607491527063151} 3\n",
            "Training vs. Validation accuracy {'Training': 0.8743866682052612, 'Validation': 0.9385665655136108} 3\n",
            "Epoch 3: \n",
            "Accuracy train:0.9313052296638489, val:0.9931740760803223\n",
            "LOSS train 0.23591213272168085 valid 0.03799313156438681\n",
            "Training vs. Validation Loss {'Training': 0.23591213272168085, 'Validation': 0.03799313156438681} 4\n",
            "Training vs. Validation accuracy {'Training': 0.9313052296638489, 'Validation': 0.9931740760803223} 4\n",
            "Epoch 4: \n",
            "Accuracy train:0.9695780277252197, val:0.9931740760803223\n",
            "LOSS train 0.11759823080725394 valid 0.028685104453567572\n",
            "Training vs. Validation Loss {'Training': 0.11759823080725394, 'Validation': 0.028685104453567572} 5\n",
            "Training vs. Validation accuracy {'Training': 0.9695780277252197, 'Validation': 0.9931740760803223} 5\n",
            "Epoch 5: \n",
            "Accuracy train:0.9803729057312012, val:0.9931740760803223\n",
            "LOSS train 0.10074097236904961 valid 0.02698522871893753\n",
            "Training vs. Validation Loss {'Training': 0.10074097236904961, 'Validation': 0.02698522871893753} 6\n",
            "Training vs. Validation accuracy {'Training': 0.9803729057312012, 'Validation': 0.9931740760803223} 6\n",
            "Epoch 6: \n",
            "Accuracy train:0.9725220799446106, val:1.0\n",
            "LOSS train 0.0986114743953714 valid 0.010549647212125516\n",
            "Training vs. Validation Loss {'Training': 0.0986114743953714, 'Validation': 0.010549647212125516} 7\n",
            "Training vs. Validation accuracy {'Training': 0.9725220799446106, 'Validation': 1.0} 7\n",
            "Epoch 7: \n",
            "Accuracy train:0.9764475226402283, val:0.9965870380401611\n",
            "LOSS train 0.10903437621891499 valid 0.01066299597005127\n",
            "Training vs. Validation Loss {'Training': 0.10903437621891499, 'Validation': 0.01066299597005127} 8\n",
            "Training vs. Validation accuracy {'Training': 0.9764475226402283, 'Validation': 0.9965870380401611} 8\n",
            "Epoch 8: \n",
            "Accuracy train:0.9774288535118103, val:0.9931740760803223\n",
            "LOSS train 0.08740523622299616 valid 0.03355987282217635\n",
            "Training vs. Validation Loss {'Training': 0.08740523622299616, 'Validation': 0.03355987282217635} 9\n",
            "Training vs. Validation accuracy {'Training': 0.9774288535118103, 'Validation': 0.9931740760803223} 9\n",
            "Epoch 9: \n",
            "Accuracy train:0.9715407490730286, val:0.9897611141204834\n",
            "LOSS train 0.0971056677114505 valid 0.03647012157853169\n",
            "Training vs. Validation Loss {'Training': 0.0971056677114505, 'Validation': 0.03647012157853169} 10\n",
            "Training vs. Validation accuracy {'Training': 0.9715407490730286, 'Validation': 0.9897611141204834} 10\n",
            "Epoch 10: \n",
            "Accuracy train:0.9705593585968018, val:0.9931740760803223\n",
            "LOSS train 0.08563425069531569 valid 0.023036905457653727\n",
            "Training vs. Validation Loss {'Training': 0.08563425069531569, 'Validation': 0.023036905457653727} 11\n",
            "Training vs. Validation accuracy {'Training': 0.9705593585968018, 'Validation': 0.9931740760803223} 11\n",
            "Epoch 11: \n",
            "Accuracy train:0.9725220799446106, val:0.9931740760803223\n",
            "LOSS train 0.09319172566756606 valid 0.03541782039663607\n",
            "Training vs. Validation Loss {'Training': 0.09319172566756606, 'Validation': 0.03541782039663607} 12\n",
            "Training vs. Validation accuracy {'Training': 0.9725220799446106, 'Validation': 0.9931740760803223} 12\n",
            "Epoch 12: \n",
            "Accuracy train:0.9793915748596191, val:0.9863481521606445\n",
            "LOSS train 0.09901875633603105 valid 0.035473171891984144\n",
            "Training vs. Validation Loss {'Training': 0.09901875633603105, 'Validation': 0.035473171891984144} 13\n",
            "Training vs. Validation accuracy {'Training': 0.9793915748596191, 'Validation': 0.9863481521606445} 13\n",
            "Epoch 13: \n",
            "Accuracy train:0.981354296207428, val:0.9931740760803223\n",
            "LOSS train 0.07817229961689848 valid 0.028290360428703327\n",
            "Training vs. Validation Loss {'Training': 0.07817229961689848, 'Validation': 0.028290360428703327} 14\n",
            "Training vs. Validation accuracy {'Training': 0.981354296207428, 'Validation': 0.9931740760803223} 14\n",
            "Epoch 14: \n",
            "Accuracy train:0.983316957950592, val:0.9863481521606445\n",
            "LOSS train 0.09065163851930545 valid 0.031685060956078814\n",
            "Training vs. Validation Loss {'Training': 0.09065163851930545, 'Validation': 0.031685060956078814} 15\n",
            "Training vs. Validation accuracy {'Training': 0.983316957950592, 'Validation': 0.9863481521606445} 15\n",
            "Epoch 15: \n",
            "Accuracy train:0.9735034108161926, val:0.9897611141204834\n",
            "LOSS train 0.07940569147467613 valid 0.029207446555422695\n",
            "Training vs. Validation Loss {'Training': 0.07940569147467613, 'Validation': 0.029207446555422695} 16\n",
            "Training vs. Validation accuracy {'Training': 0.9735034108161926, 'Validation': 0.9897611141204834} 16\n",
            "Epoch 16: \n",
            "Accuracy train:0.9784101843833923, val:0.9897611141204834\n",
            "LOSS train 0.09749738657130645 valid 0.039048264789016685\n",
            "Training vs. Validation Loss {'Training': 0.09749738657130645, 'Validation': 0.039048264789016685} 17\n",
            "Training vs. Validation accuracy {'Training': 0.9784101843833923, 'Validation': 0.9897611141204834} 17\n",
            "Epoch 17: \n",
            "Accuracy train:0.9715407490730286, val:0.9965870380401611\n",
            "LOSS train 0.08323071968670075 valid 0.024702875743969344\n",
            "Training vs. Validation Loss {'Training': 0.08323071968670075, 'Validation': 0.024702875743969344} 18\n",
            "Training vs. Validation accuracy {'Training': 0.9715407490730286, 'Validation': 0.9965870380401611} 18\n",
            "Epoch 18: \n",
            "Accuracy train:0.9744848012924194, val:0.979522168636322\n",
            "LOSS train 0.08176179144244927 valid 0.06202574276312589\n",
            "Training vs. Validation Loss {'Training': 0.08176179144244927, 'Validation': 0.06202574276312589} 19\n",
            "Training vs. Validation accuracy {'Training': 0.9744848012924194, 'Validation': 0.979522168636322} 19\n",
            "Epoch 19: \n",
            "Accuracy train:0.9685966372489929, val:0.9931740760803223\n",
            "LOSS train 0.07702386647892687 valid 0.014386879374190661\n",
            "Training vs. Validation Loss {'Training': 0.07702386647892687, 'Validation': 0.014386879374190661} 20\n",
            "Training vs. Validation accuracy {'Training': 0.9685966372489929, 'Validation': 0.9931740760803223} 20\n",
            "Epoch 20: \n",
            "Accuracy train:0.981354296207428, val:0.9931740760803223\n",
            "LOSS train 0.06764529806633408 valid 0.03262515821127939\n",
            "Training vs. Validation Loss {'Training': 0.06764529806633408, 'Validation': 0.03262515821127939} 21\n",
            "Training vs. Validation accuracy {'Training': 0.981354296207428, 'Validation': 0.9931740760803223} 21\n",
            "Epoch 21: \n",
            "Accuracy train:0.9793915748596191, val:0.9897611141204834\n",
            "LOSS train 0.07469235908669922 valid 0.014405553894600112\n",
            "Training vs. Validation Loss {'Training': 0.07469235908669922, 'Validation': 0.014405553894600112} 22\n",
            "Training vs. Validation accuracy {'Training': 0.9793915748596191, 'Validation': 0.9897611141204834} 22\n",
            "Epoch 22: \n",
            "Accuracy train:0.9842983484268188, val:0.9965870380401611\n",
            "LOSS train 0.0838976798292536 valid 0.01748991899664058\n",
            "Training vs. Validation Loss {'Training': 0.0838976798292536, 'Validation': 0.01748991899664058} 23\n",
            "Training vs. Validation accuracy {'Training': 0.9842983484268188, 'Validation': 0.9965870380401611} 23\n",
            "Epoch 23: \n",
            "Accuracy train:0.9793915748596191, val:0.9897611141204834\n",
            "LOSS train 0.05860478896647692 valid 0.03523301221211265\n",
            "Training vs. Validation Loss {'Training': 0.05860478896647692, 'Validation': 0.03523301221211265} 24\n",
            "Training vs. Validation accuracy {'Training': 0.9793915748596191, 'Validation': 0.9897611141204834} 24\n",
            "Epoch 24: \n",
            "Accuracy train:0.983316957950592, val:0.9829351305961609\n",
            "LOSS train 0.062035673297941685 valid 0.03902262585231142\n",
            "Training vs. Validation Loss {'Training': 0.062035673297941685, 'Validation': 0.03902262585231142} 25\n",
            "Training vs. Validation accuracy {'Training': 0.983316957950592, 'Validation': 0.9829351305961609} 25\n",
            "Epoch 25: \n",
            "Accuracy train:0.9774288535118103, val:0.9829351305961609\n",
            "LOSS train 0.09688782845981993 valid 0.05009798908698334\n",
            "Training vs. Validation Loss {'Training': 0.09688782845981993, 'Validation': 0.05009798908698334} 26\n",
            "Training vs. Validation accuracy {'Training': 0.9774288535118103, 'Validation': 0.9829351305961609} 26\n",
            "Epoch 26: \n",
            "Accuracy train:0.9764475226402283, val:0.9931740760803223\n",
            "LOSS train 0.09480798129852001 valid 0.016731445927992656\n",
            "Training vs. Validation Loss {'Training': 0.09480798129852001, 'Validation': 0.016731445927992656} 27\n",
            "Training vs. Validation accuracy {'Training': 0.9764475226402283, 'Validation': 0.9931740760803223} 27\n",
            "Epoch 27: \n",
            "Accuracy train:0.9705593585968018, val:0.9863481521606445\n",
            "LOSS train 0.08540098841946858 valid 0.027730150791588432\n",
            "Training vs. Validation Loss {'Training': 0.08540098841946858, 'Validation': 0.027730150791588432} 28\n",
            "Training vs. Validation accuracy {'Training': 0.9705593585968018, 'Validation': 0.9863481521606445} 28\n",
            "Epoch 28: \n",
            "Accuracy train:0.9764475226402283, val:0.9897611141204834\n",
            "LOSS train 0.073249745182693 valid 0.025041778612224636\n",
            "Training vs. Validation Loss {'Training': 0.073249745182693, 'Validation': 0.025041778612224636} 29\n",
            "Training vs. Validation accuracy {'Training': 0.9764475226402283, 'Validation': 0.9897611141204834} 29\n",
            "Epoch 29: \n",
            "Accuracy train:0.9793915748596191, val:0.979522168636322\n",
            "LOSS train 0.060424765571951866 valid 0.04899188166761329\n",
            "Training vs. Validation Loss {'Training': 0.060424765571951866, 'Validation': 0.04899188166761329} 30\n",
            "Training vs. Validation accuracy {'Training': 0.9793915748596191, 'Validation': 0.979522168636322} 30\n",
            "Epoch 30: \n",
            "Accuracy train:0.9754661321640015, val:0.9931740760803223\n",
            "LOSS train 0.07139351226102847 valid 0.025999408467517544\n",
            "Training vs. Validation Loss {'Training': 0.07139351226102847, 'Validation': 0.025999408467517544} 31\n",
            "Training vs. Validation accuracy {'Training': 0.9754661321640015, 'Validation': 0.9931740760803223} 31\n",
            "Epoch 31: \n",
            "Accuracy train:0.981354296207428, val:0.9897611141204834\n",
            "LOSS train 0.07198355837653463 valid 0.032110033517417\n",
            "Training vs. Validation Loss {'Training': 0.07198355837653463, 'Validation': 0.032110033517417} 32\n",
            "Training vs. Validation accuracy {'Training': 0.981354296207428, 'Validation': 0.9897611141204834} 32\n",
            "Epoch 32: \n",
            "Accuracy train:0.9705593585968018, val:0.9624573588371277\n",
            "LOSS train 0.11438632419762704 valid 0.09521045998159632\n",
            "Training vs. Validation Loss {'Training': 0.11438632419762704, 'Validation': 0.09521045998159632} 33\n",
            "Training vs. Validation accuracy {'Training': 0.9705593585968018, 'Validation': 0.9624573588371277} 33\n",
            "Epoch 33: \n",
            "Accuracy train:0.9784101843833923, val:0.9897611141204834\n",
            "LOSS train 0.09493871620641305 valid 0.02444296677701156\n",
            "Training vs. Validation Loss {'Training': 0.09493871620641305, 'Validation': 0.02444296677701156} 34\n",
            "Training vs. Validation accuracy {'Training': 0.9784101843833923, 'Validation': 0.9897611141204834} 34\n",
            "Epoch 34: \n",
            "Accuracy train:0.9793915748596191, val:0.9897611141204834\n",
            "LOSS train 0.07224358761539826 valid 0.020229012348750075\n",
            "Training vs. Validation Loss {'Training': 0.07224358761539826, 'Validation': 0.020229012348750075} 35\n",
            "Training vs. Validation accuracy {'Training': 0.9793915748596191, 'Validation': 0.9897611141204834} 35\n",
            "Epoch 35: \n",
            "Accuracy train:0.983316957950592, val:0.9897611141204834\n",
            "LOSS train 0.05309321518199375 valid 0.023150667512860917\n",
            "Training vs. Validation Loss {'Training': 0.05309321518199375, 'Validation': 0.023150667512860917} 36\n",
            "Training vs. Validation accuracy {'Training': 0.983316957950592, 'Validation': 0.9897611141204834} 36\n",
            "Epoch 36: \n",
            "Accuracy train:0.9892051219940186, val:0.9931740760803223\n",
            "LOSS train 0.0770894642919302 valid 0.022314279537302657\n",
            "Training vs. Validation Loss {'Training': 0.0770894642919302, 'Validation': 0.022314279537302657} 37\n",
            "Training vs. Validation accuracy {'Training': 0.9892051219940186, 'Validation': 0.9931740760803223} 37\n",
            "Epoch 37: \n",
            "Accuracy train:0.9803729057312012, val:0.979522168636322\n",
            "LOSS train 0.05852916575251864 valid 0.033612959298466194\n",
            "Training vs. Validation Loss {'Training': 0.05852916575251864, 'Validation': 0.033612959298466194} 38\n",
            "Training vs. Validation accuracy {'Training': 0.9803729057312012, 'Validation': 0.979522168636322} 38\n",
            "Epoch 38: \n",
            "Accuracy train:0.981354296207428, val:0.9931740760803223\n",
            "LOSS train 0.06603429316041562 valid 0.017570040798394377\n",
            "Training vs. Validation Loss {'Training': 0.06603429316041562, 'Validation': 0.017570040798394377} 39\n",
            "Training vs. Validation accuracy {'Training': 0.981354296207428, 'Validation': 0.9931740760803223} 39\n",
            "Epoch 39: \n",
            "Accuracy train:0.9872424006462097, val:0.9931740760803223\n",
            "LOSS train 0.06700515597521399 valid 0.020218038508043417\n",
            "Training vs. Validation Loss {'Training': 0.06700515597521399, 'Validation': 0.020218038508043417} 40\n",
            "Training vs. Validation accuracy {'Training': 0.9872424006462097, 'Validation': 0.9931740760803223} 40\n",
            "Epoch 40: \n",
            "Accuracy train:0.983316957950592, val:0.9897611141204834\n",
            "LOSS train 0.06090313255285414 valid 0.03324175138804245\n",
            "Training vs. Validation Loss {'Training': 0.06090313255285414, 'Validation': 0.03324175138804245} 41\n",
            "Training vs. Validation accuracy {'Training': 0.983316957950592, 'Validation': 0.9897611141204834} 41\n",
            "Epoch 41: \n",
            "Accuracy train:0.9852796792984009, val:0.9897611141204834\n",
            "LOSS train 0.05164710561243387 valid 0.011955197642312973\n",
            "Training vs. Validation Loss {'Training': 0.05164710561243387, 'Validation': 0.011955197642312973} 42\n",
            "Training vs. Validation accuracy {'Training': 0.9852796792984009, 'Validation': 0.9897611141204834} 42\n",
            "Epoch 42: \n",
            "Accuracy train:0.9882237315177917, val:0.9931740760803223\n",
            "LOSS train 0.052101708662051424 valid 0.023521599474387738\n",
            "Training vs. Validation Loss {'Training': 0.052101708662051424, 'Validation': 0.023521599474387738} 43\n",
            "Training vs. Validation accuracy {'Training': 0.9882237315177917, 'Validation': 0.9931740760803223} 43\n",
            "Epoch 43: \n",
            "Accuracy train:0.9803729057312012, val:0.9897611141204834\n",
            "LOSS train 0.051414281026854254 valid 0.021552158371719088\n",
            "Training vs. Validation Loss {'Training': 0.051414281026854254, 'Validation': 0.021552158371719088} 44\n",
            "Training vs. Validation accuracy {'Training': 0.9803729057312012, 'Validation': 0.9897611141204834} 44\n",
            "Epoch 44: \n",
            "Accuracy train:0.9784101843833923, val:0.9931740760803223\n",
            "LOSS train 0.07402238050977197 valid 0.02808378688212561\n",
            "Training vs. Validation Loss {'Training': 0.07402238050977197, 'Validation': 0.02808378688212561} 45\n",
            "Training vs. Validation accuracy {'Training': 0.9784101843833923, 'Validation': 0.9931740760803223} 45\n",
            "Epoch 45: \n",
            "Accuracy train:0.98233562707901, val:0.9761092066764832\n",
            "LOSS train 0.060005147404109054 valid 0.08803044759399252\n",
            "Training vs. Validation Loss {'Training': 0.060005147404109054, 'Validation': 0.08803044759399252} 46\n",
            "Training vs. Validation accuracy {'Training': 0.98233562707901, 'Validation': 0.9761092066764832} 46\n",
            "Early stopping at epoch 45\n",
            "tensor(0.9761)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list_label = label_dict_from_config_file(\"hand_gesture.yaml\")\n",
        "DATA_FOLDER_PATH=\"./data/\"\n",
        "testset = CustomImageDataset(os.path.join(DATA_FOLDER_PATH,\"landmark_test.csv\"))\n",
        "\n",
        "# Test DataLoader instantiation\n",
        "################## Your Code Here ################## Q6\n",
        "''' Hoàn thành code bên dưới để  khởi tạo DataLoader cho testset with batch size\n",
        "20, không cho phép shuffle\n",
        "'''\n",
        "test_loader = torch.utils.data.DataLoader(testset,batch_size=20, shuffle=False)\n",
        "####################################################\n",
        "\n",
        "\n",
        "\n",
        "network = NeuralNetwork()\n",
        "network.load_state_dict(torch.load(best_model_path, weights_only=False))\n",
        "\n",
        "network.eval()\n",
        "acc_test = Accuracy(num_classes=len(list_label), task='MULTICLASS')\n",
        "for i, test_data in enumerate(test_loader):\n",
        "    test_input, test_label = test_data\n",
        "    ################## Your Code Here ################## Q7\n",
        "    '''Hoàn thành code bên dưới để  predict class của cử chỉ và update accuracy\n",
        "    với kết quả predict và true labels\n",
        "    '''\n",
        "    preds = model(test_input)\n",
        "    acc_test.update(model.predict_with_known_class(test_input), test_label)\n",
        "\n",
        "    ####################################################\n",
        "\n",
        "print(network.__class__.__name__)\n",
        "print(f\"Accuracy of model:{acc_test.compute().item()}\")\n",
        "print(\"========================================================================\")"
      ],
      "metadata": {
        "id": "WuKEiiC_BWDM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f267a3e5-c53d-4460-fe88-a3497fc2d1d8"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork\n",
            "Accuracy of model:0.9685039520263672\n",
            "========================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "569TTudlZoz6"
      },
      "execution_count": 26,
      "outputs": []
    }
  ]
}